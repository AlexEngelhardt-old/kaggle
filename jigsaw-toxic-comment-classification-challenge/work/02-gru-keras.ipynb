{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocess import preprocess  # local file. restart kernel if this changed, it won't be re-imported otherwise\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Read the first few rows during crude developing:\n",
    "train = pd.read_csv('data/train.csv', nrows=1000).fillna(' ')\n",
    "test = pd.read_csv('data/test.csv', nrows=1000).fillna(' ')\n",
    "\n",
    "## These lines load all data:\n",
    "#train = pd.read_csv('data/train.csv').fillna(' ')\n",
    "#test = pd.read_csv('data/test.csv').fillna(' ')\n",
    "\n",
    "[train, test, train_text, test_text, all_text, class_names] = preprocess(train, test)\n",
    "\n",
    "# TODO why does a train dev split break the code?\n",
    "# train, dev = train_test_split(train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.105\n",
       "severe_toxic     0.009\n",
       "obscene          0.049\n",
       "threat           0.004\n",
       "insult           0.054\n",
       "identity_hate    0.009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[class_names].mean()  # imbalanced => baseline of 96% accuracy for \"predict all as okay\"\n",
    "# preds: [0.07195416, 0.00958922, 0.03911009, 0.00467693, 0.04485368, 0.00369948]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dev.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "import glove as glv\n",
    "g_vectors, words_to_index, index_to_words = glv.loadGloveModel(\"data/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in words_to_index:\n",
    "    if words_to_index[v] < 0:\n",
    "        print(\"OMG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38497 ,  0.80092 ,  0.064106, -0.28355 , -0.026759, -0.34532 ,\n",
       "       -0.64253 , -0.11729 , -0.33257 ,  0.55243 , -0.087813,  0.9035  ,\n",
       "        0.47102 ,  0.56657 ,  0.6985  , -0.35229 , -0.86542 ,  0.90573 ,\n",
       "        0.03576 , -0.071705, -0.12327 ,  0.54923 ,  0.47005 ,  0.35572 ,\n",
       "        1.2611  , -0.67581 , -0.94983 ,  0.68666 ,  0.3871  , -1.3492  ,\n",
       "        0.63512 ,  0.46416 , -0.48814 ,  0.83827 , -0.9246  , -0.33722 ,\n",
       "        0.53741 , -1.0616  , -0.081403, -0.67111 ,  0.30923 , -0.3923  ,\n",
       "       -0.55002 , -0.68827 ,  0.58049 , -0.11626 ,  0.013139, -0.57654 ,\n",
       "        0.048833,  0.67204 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_vectors[\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = train['comment_text'].str.split().apply(len).max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[class_names].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'were',\n",
       " 'reverted?',\n",
       " 'they',\n",
       " \"weren't\",\n",
       " 'vandalisms,',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'gas',\n",
       " 'after',\n",
       " 'i',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'new',\n",
       " 'york',\n",
       " 'dolls',\n",
       " 'fac.',\n",
       " 'and',\n",
       " 'please',\n",
       " \"don't\",\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " \"i'm\",\n",
       " 'retired',\n",
       " 'now.89.205.38.27']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].iloc[0].lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from lstm_utils import sentences_to_indices, pretrained_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, GRU, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "def TheModel(input_shape, g_vectors, words_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the GRU model\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    sentence_indices = Input(shape = input_shape, dtype = 'int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(g_vectors, words_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    # X = LSTM(units = 128, return_sequences = True)(embeddings)\n",
    "    X = GRU(units = 128, kernel_initializer = 'glorot_uniform', recurrent_initializer = 'glorot_uniform')(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(rate = 0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    #X = LSTM(units = 128)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    #X = Dropout(rate = 0.5)(X)\n",
    "    # Propagate X through a Dense (=FC) layer\n",
    "    X = Dense(units = 6)(X)  # 6 units because \n",
    "    # Add a sigmoid activation because we have multilabel classification\n",
    "    X = Activation(\"sigmoid\", name = \"sigmoid_activation\")(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs = sentence_indices, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TheModel((max_len, ), g_vectors, words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1052)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1052, 50)          20000050  \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               68736     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "_________________________________________________________________\n",
      "sigmoid_activation (Activati (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 20,069,560\n",
      "Trainable params: 69,510\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/2166\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train.as_matrix(columns = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(train['comment_text'], words_to_index, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1052)\n",
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_indices.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4251 - acc: 0.9612\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1610 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1565 - acc: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84e4545d30>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train, epochs = 3, batch_size = 32, shuffle=True)\n",
    "\n",
    "# Plot loss function during training:\n",
    "# https://www.kaggle.com/parasjindal96/basic-deep-learning-tutorial-using-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file = \"keras-model.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 8s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9616666622161866"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train_indices, Y_train)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09977868, 0.01022341, 0.0461725 , 0.00577286, 0.04667644,\n",
       "        0.01186479],\n",
       "       [0.09977868, 0.01022341, 0.0461725 , 0.00577286, 0.04667645,\n",
       "        0.01186479],\n",
       "       [0.09977868, 0.01022341, 0.04617248, 0.00577286, 0.04667645,\n",
       "        0.01186479],\n",
       "       ...,\n",
       "       [0.09977868, 0.01022341, 0.04617248, 0.00577286, 0.04667645,\n",
       "        0.01186479],\n",
       "       [0.09977868, 0.01022341, 0.04617248, 0.00577286, 0.04667645,\n",
       "        0.01186479],\n",
       "       [0.09977868, 0.01022341, 0.0461725 , 0.00577286, 0.04667644,\n",
       "        0.01186479]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max_len_dev = dev['comment_text'].str.split().apply(len).max()\n",
    "#max_len_dev = max_len\n",
    "#\n",
    "#X_dev_indices = sentences_to_indices(dev['comment_text'], words_to_index, max_len_dev)\n",
    "#\n",
    "#Y_dev = dev.as_matrix(columns = class_names)\n",
    "#\n",
    "#loss, acc = model.evaluate(X_dev_indices, Y_dev)\n",
    "#print()\n",
    "#print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code allows you to see the mislabelled examples\n",
    "#C = 5\n",
    "#y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "#X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "#pred = model.predict(X_test_indices)\n",
    "#for i in range(len(X_test)):\n",
    "#    x = X_test_indices\n",
    "#    num = np.argmax(pred[i])\n",
    "#    if(num != Y_test[i]):\n",
    "#        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 8s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# max_len_test = test['comment_text'].str.split().apply(len).max()\n",
    "max_len_test = max_len\n",
    "\n",
    "X_test_indices = sentences_to_indices(test['comment_text'], words_to_index, max_len_test)\n",
    "\n",
    "Y_test = test.as_matrix(columns = class_names)\n",
    "\n",
    "preds = model.predict(X_test_indices, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[394017,  77181, 194532, ...,      0,      0,      0],\n",
       "       [     0, 154323, 307569, ...,      0,      0,      0]], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_indices[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07195413, 0.00958922, 0.03911008, 0.00467692, 0.04485367,\n",
       "        0.00369947],\n",
       "       [0.07195416, 0.00958922, 0.03911009, 0.00467693, 0.04485369,\n",
       "        0.00369947]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_indices[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07195413, 0.00958922, 0.03911008, 0.00467692, 0.04485367,\n",
       "        0.00369947],\n",
       "       [0.07195416, 0.00958922, 0.03911009, 0.00467693, 0.04485368,\n",
       "        0.00369948],\n",
       "       [0.07195413, 0.00958922, 0.03911008, 0.00467692, 0.04485368,\n",
       "        0.00369948],\n",
       "       ...,\n",
       "       [0.07195413, 0.00958922, 0.03911008, 0.00467692, 0.04485368,\n",
       "        0.00369947],\n",
       "       [0.07195416, 0.00958922, 0.03911008, 0.00467692, 0.04485368,\n",
       "        0.00369948],\n",
       "       [0.07195413, 0.00958922, 0.03911007, 0.00467692, 0.04485368,\n",
       "        0.00369947]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.03911</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "5  0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...   \n",
       "7  000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "8  00025358d4737918  \" \\n Only a fool can believe in such numbers. ...   \n",
       "9  00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...   \n",
       "\n",
       "      toxic  severe_toxic  obscene    threat    insult  identity_hate  \n",
       "0  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "1  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "2  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "3  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "4  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "5  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "6  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "7  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "8  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  \n",
       "9  0.071954      0.009589  0.03911  0.004677  0.044854       0.003699  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    class_name = class_names[i]\n",
    "    test[class_name] = preds[:, i]\n",
    "    \n",
    "test.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9401147e-16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(test['toxic'])  # oh-oh :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
